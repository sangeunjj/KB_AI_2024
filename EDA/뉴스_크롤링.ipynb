{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformersNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading transformers-4.43.4-py3-none-any.whl.metadata (43 kB)\n",
      "     -------------------------------------- 43.7/43.7 kB 711.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\python\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python\\lib\\site-packages (from transformers) (1.22.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python\\lib\\site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python\\lib\\site-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\python\\lib\\site-packages (from transformers) (2020.6.8)\n",
      "Requirement already satisfied: requests in c:\\python\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.4-cp38-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp38-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\python\\lib\\site-packages (from transformers) (4.47.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.2->transformers)\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting packaging>=20.0 (from transformers)\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\lib\\site-packages (from requests->transformers) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\lib\\site-packages (from requests->transformers) (2020.6.20)\n",
      "Downloading transformers-4.43.4-py3-none-any.whl (9.4 MB)\n",
      "   ---------------------------------------- 9.4/9.4 MB 6.1 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
      "   ---------------------------------------- 417.5/417.5 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "   ---------------------------------------- 54.0/54.0 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.4-cp38-none-win_amd64.whl (286 kB)\n",
      "   ---------------------------------------- 286.2/286.2 kB 5.9 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp38-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 2.2/2.2 MB 7.4 MB/s eta 0:00:00\n",
      "Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "   ---------------------------------------- 177.6/177.6 kB 2.7 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, packaging, fsspec, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.4\n",
      "    Uninstalling packaging-20.4:\n",
      "      Successfully uninstalled packaging-20.4\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 0.7.4\n",
      "    Uninstalling fsspec-0.7.4:\n",
      "      Successfully uninstalled fsspec-0.7.4\n",
      "\n",
      "Successfully installed fsspec-2024.6.1 huggingface-hub-0.24.5 packaging-24.1 safetensors-0.4.4 tokenizers-0.19.1 transformers-4.43.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\python\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\python\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python\\lib\\site-packages)\n",
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 4.1.4 requires pyqt5<5.13; python_version >= \"3\", which is not installed.\n",
      "spyder 4.1.4 requires pyqtwebengine<5.13; python_version >= \"3\", which is not installed.\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\python\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\python\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\python\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\python\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\python\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\python\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in c:\\python\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Collecting numpy<1.19.0,>=1.16.0 (from tensorflow)\n",
      "  Using cached numpy-1.18.5-cp38-cp38-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\python\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\python\\lib\\site-packages (from tensorflow) (3.12.4)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in c:\\python\\lib\\site-packages (from tensorflow) (2.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in c:\\python\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\python\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\python\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\python\\lib\\site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\python\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Collecting scipy==1.4.1 (from tensorflow)\n",
      "  Using cached scipy-1.4.1-cp38-cp38-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\python\\lib\\site-packages (from tensorflow) (1.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\python\\lib\\site-packages (from protobuf>=3.9.2->tensorflow) (49.2.0.post20200714)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\python\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.20.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\python\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\python\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\python\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\python\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\python\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\python\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\python\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\python\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\python\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\python\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Using cached scipy-1.4.1-cp38-cp38-win_amd64.whl (31.0 MB)\n",
      "Using cached numpy-1.18.5-cp38-cp38-win_amd64.whl (12.8 MB)\n",
      "Installing collected packages: numpy, scipy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.10.1\n",
      "    Uninstalling scipy-1.10.1:\n",
      "      Successfully uninstalled scipy-1.10.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\python\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python\\lib\\site-packages)\n",
      "WARNING: Error parsing dependencies of pyodbc: Invalid version: '4.0.0-unsupported'\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\python\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python\\lib\\site-packages)\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\python\\Lib\\site-packages\\~%mpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 483, in run\n",
      "    installed_versions[distribution.canonical_name] = distribution.version\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_internal\\metadata\\pkg_resources.py\", line 192, in version\n",
      "    return parse_version(self._dist.version)\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 56, in parse\n",
      "    return Version(version)\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 202, in __init__\n",
      "    raise InvalidVersion(f\"Invalid version: '{version}'\")\n",
      "pip._vendor.packaging.version.InvalidVersion: Invalid version: '4.0.0-unsupported'\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.tsl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5eba17a4b841>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPreTrainedTokenizerFast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBartForConditionalGeneration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# 페이지 url 형식에 맞게 바꾸어 주는 함수 만들기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmonitoring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpydev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python\\lib\\site-packages\\tensorflow\\python\\eager\\monitoring.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python\\lib\\site-packages\\tensorflow\\core\\framework\\summary_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhistogram_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtensorflow_dot_tsl_dot_protobuf_dot_histogram__pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_tensor__pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.tsl'"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
    "import tensorflow as tf\n",
    "\n",
    "# 페이지 url 형식에 맞게 바꾸어 주는 함수 만들기\n",
    "def makePgNum(num):\n",
    "    if num == 1:\n",
    "        return num\n",
    "    elif num == 0:\n",
    "        return num + 1\n",
    "    else:\n",
    "        return num + 9 * (num - 1)\n",
    "\n",
    "# 크롤링할 url 생성하는 함수 만들기(검색어, 크롤링 시작 페이지, 크롤링 종료 페이지)\n",
    "def makeUrl(search, start_pg, end_pg):\n",
    "    if start_pg == end_pg:\n",
    "        start_page = makePgNum(start_pg)\n",
    "        url = \"https://search.naver.com/search.naver?where=news&sm=tab_pge&query=\" + search + \"&start=\" + str(start_page)\n",
    "        return url\n",
    "    else:\n",
    "        urls = []\n",
    "        for i in range(start_pg, end_pg + 1):\n",
    "            page = makePgNum(i)\n",
    "            url = \"https://search.naver.com/search.naver?where=news&sm=tab_pge&query=\" + search + \"&start=\" + str(page)\n",
    "            urls.append(url)\n",
    "        return urls    \n",
    "\n",
    "# html에서 원하는 속성 추출하는 함수 만들기 (기사, 추출하려는 속성값)\n",
    "def news_attrs_crawler(articles, attrs):\n",
    "    attrs_content = []\n",
    "    for i in articles:\n",
    "        attrs_content.append(i.attrs[attrs])\n",
    "    return attrs_content\n",
    "\n",
    "# ConnectionError방지\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/98.0.4758.102\"}\n",
    "\n",
    "#html생성해서 기사크롤링하는 함수 만들기(url): 링크를 반환\n",
    "def articles_crawler(url):\n",
    "    original_html = requests.get(url, headers=headers)\n",
    "    html = BeautifulSoup(original_html.text, \"html.parser\")\n",
    "\n",
    "    url_naver = html.select(\"div.group_news > ul.list_news > li div.news_area > div.news_info > div.info_group > a.info\")\n",
    "    url = news_attrs_crawler(url_naver, 'href')\n",
    "    return url\n",
    "\n",
    "# 기사 크롤링 및 요약 함수\n",
    "def summarize_articles(company_name, start_page=1, end_page=300):   #### 몇페이지까지 크롤링할건지 정하기\n",
    "    # naver url 생성\n",
    "    url = makeUrl(company_name, start_page, end_page)\n",
    "\n",
    "    # 뉴스 크롤러 실행\n",
    "    news_titles = []\n",
    "    news_contents = []\n",
    "    final_urls = []\n",
    "    for i in url:\n",
    "        urls = articles_crawler(i)\n",
    "        for link in urls:\n",
    "            if \"news.naver.com\" in link:\n",
    "                final_urls.append(link)\n",
    "\n",
    "    # 뉴스 내용 크롤링\n",
    "    for i in tqdm(final_urls, desc=f\"크롤링 {company_name}\"):\n",
    "        # 각 기사 html get하기\n",
    "        news = requests.get(i, headers=headers)\n",
    "        news_html = BeautifulSoup(news.text, \"html.parser\")\n",
    "\n",
    "        # 뉴스 제목 가져오기\n",
    "        title = news_html.select_one(\"#ct > div.media_end_head.go_trans > div.media_end_head_title > h2\")\n",
    "        if title is None:\n",
    "            title = news_html.select_one(\"#content > div.end_ct > div > h2\")\n",
    "        \n",
    "        # 뉴스 본문 가져오기\n",
    "        content = news_html.select(\"article#dic_area\")\n",
    "        if not content:\n",
    "            content = news_html.select(\"#articeBody\")\n",
    "\n",
    "        # 기사 텍스트만 가져오기\n",
    "        content = ''.join(str(content))\n",
    "\n",
    "        # html태그제거 및 텍스트 다듬기\n",
    "        pattern1 = '<[^>]*>'\n",
    "        title = re.sub(pattern=pattern1, repl='', string=str(title))\n",
    "        content = re.sub(pattern=pattern1, repl='', string=content)\n",
    "        pattern2 = \"\"\"[\\n\\n\\n\\n\\n// flash 오류를 우회하기 위한 함수 추가\\nfunction _flash_removeCallback() {}\"\"\"\n",
    "        content = content.replace(pattern2, '')\n",
    "\n",
    "        if title and content:\n",
    "            news_titles.append(title)\n",
    "            news_contents.append(content)\n",
    "\n",
    "    # 크롤링한 기사가 없으면 빈 문자열 반환\n",
    "    if not news_contents:\n",
    "        return \"\"\n",
    "\n",
    "    # 크롤링한 기사 내용을 하나의 텍스트로 합치기\n",
    "    combined_text = \" \".join(news_contents)\n",
    "\n",
    "    # KoBART 토크나이저와 모델 로드\n",
    "    tokenizer = PreTrainedTokenizerFast.from_pretrained('gogamza/kobart-base-v2')\n",
    "    model = BartForConditionalGeneration.from_pretrained('gogamza/kobart-base-v2')\n",
    "\n",
    "    # 입력 텍스트의 길이 제한 설정\n",
    "    max_input_length = 1024\n",
    "\n",
    "    # 입력 텍스트 길이 조정\n",
    "    if len(combined_text) > max_input_length:\n",
    "        combined_text = combined_text[:max_input_length]\n",
    "\n",
    "    # 입력 텍스트 토큰화\n",
    "    inputs = tokenizer(combined_text, max_length=max_input_length, return_tensors='pt', truncation=True)\n",
    "\n",
    "    # 요약 생성\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=80, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "    # 요약 결과 디코딩\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return summary\n",
    "\n",
    "# 엑셀 파일에서 데이터 불러오기\n",
    "file_path = './전체기업.csv'  # 엑셀 파일 경로\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 뉴스 요약 컬럼 생성\n",
    "df['뉴스요약'] = ''\n",
    "\n",
    "# 기업명별로 뉴스 요약 생성하여 추가\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"전체 진행\"):\n",
    "    company_name = row['corp_name']\n",
    "    summary = summarize_articles(company_name)\n",
    "    df.at[index, '뉴스요약'] = summary\n",
    "\n",
    "# 최종 결과를 엑셀 파일로 저장\n",
    "output_path = './기업별_뉴스요약_결과.csv'  # 결과 파일 경로\n",
    "df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"모든 기업에 대한 뉴스 요약이 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'·\\'\\'\\'\\'→\\'\\' 한 단계 상향...역대 가장 높아\"2년간 의미있는 수준 수익성 개선 시현\"\\n\\n\\n\\n\\n[이천=뉴시스] 김종택 기자 = SK하이닉스가 올해 2분기(4~6월) 올해 2분기(4~6월) 역대 최대 분기 매출을 달성했다. 영업이익도 역대 3번째로 많은 큰 큰 큰 큰 큰 큰 큰 큰 큰 큰 큰으로, 6년 만에 5조원대의 이익을 냈다. SK하이닉스는 올해 2분기 매출 16조4233억원, 영업이익 5조4685억원의억원의 실적을 기록했다고 25일 밝혔다. 매출은 전년 7조3059억원보다 124.8% 증가했고, 영업손익도 전년 2조8821억원 적자 대비 흑자 전환에 성공했다. 사진은'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['뉴스요약'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\python\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\python\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python\\lib\\site-packages)\n",
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading torch-2.4.0-cp38-cp38-win_amd64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: filelock in c:\\python\\lib\\site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\python\\lib\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\python\\lib\\site-packages (from torch) (1.6.1)\n",
      "Requirement already satisfied: networkx in c:\\python\\lib\\site-packages (from torch) (2.4)\n",
      "Requirement already satisfied: jinja2 in c:\\python\\lib\\site-packages (from torch) (2.11.2)\n",
      "Requirement already satisfied: fsspec in c:\\python\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\python\\lib\\site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\python\\lib\\site-packages (from networkx->torch) (4.4.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\python\\lib\\site-packages (from sympy->torch) (1.1.0)\n",
      "Downloading torch-2.4.0-cp38-cp38-win_amd64.whl (198.1 MB)\n",
      "   ---------------------------------------- 198.1/198.1 MB 5.4 MB/s eta 0:00:00\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.4.0\n"
     ]
    }
   ],
   "source": [
    "# PyTorch 설치 (CPU 버전)\n",
    "!pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu117\n",
      "Requirement already satisfied: torch in c:\\python\\lib\\site-packages (2.4.0)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu117/torchvision-0.15.2%2Bcu117-cp38-cp38-win_amd64.whl (4.9 MB)\n",
      "     ---------------------------------------- 4.9/4.9 MB 6.7 MB/s eta 0:00:00\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu117/torchaudio-2.0.2%2Bcu117-cp38-cp38-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\python\\lib\\site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\python\\lib\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\python\\lib\\site-packages (from torch) (1.6.1)\n",
      "Requirement already satisfied: networkx in c:\\python\\lib\\site-packages (from torch) (2.4)\n",
      "Requirement already satisfied: jinja2 in c:\\python\\lib\\site-packages (from torch) (2.11.2)\n",
      "Requirement already satisfied: fsspec in c:\\python\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: numpy in c:\\python\\lib\\site-packages (from torchvision) (1.22.1)\n",
      "Requirement already satisfied: requests in c:\\python\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu117/torch-2.0.1%2Bcu117-cp38-cp38-win_amd64.whl (2343.7 MB)\n",
      "     --------------------------------         1.9/2.3 GB 7.8 MB/s eta 0:00:53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\python\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python\\lib\\site-packages)\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 98, in read\n",
      "    data: bytes = self.__fp.read(amt)\n",
      "  File \"C:\\python\\lib\\http\\client.py\", line 454, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"C:\\python\\lib\\http\\client.py\", line 498, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"C:\\python\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\python\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\python\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 180, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 245, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 377, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 95, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 546, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 427, in resolve\n",
      "    failure_causes = self._attempt_to_pin_criterion(name)\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 239, in _attempt_to_pin_criterion\n",
      "    criteria = self._get_updated_criteria(candidate)\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 230, in _get_updated_criteria\n",
      "    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 173, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 156, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 155, in __bool__\n",
      "    return any(self)\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 143, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 47, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 211, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 293, in __init__\n",
      "    super().__init__(\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 156, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 225, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 304, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 525, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 596, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 168, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 109, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 147, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 587, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"C:\\python\\lib\\contextlib.py\", line 131, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"C:\\python\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='download.pytorch.org', port=443): Read timed out.\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# PyTorch 설치 (CUDA를 지원하는 GPU 버전, NVIDIA GPU 사용 시)\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네이버 코드 보고 데이터 생성 코드 다시 짜봄."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 페이지 url 형식에 맞게 바꾸어 주는 함수 만들기\n",
    "  #입력된 수를 1, 11, 21, 31 ...만들어 주는 함수\n",
    "def makePgNum(num):\n",
    "    if num == 1:\n",
    "        return num\n",
    "    elif num == 0:\n",
    "        return num+1\n",
    "    else:\n",
    "        return num+9*(num-1)\n",
    "\n",
    "# 크롤링할 url 생성하는 함수 만들기(검색어, 크롤링 시작 페이지, 크롤링 종료 페이지)\n",
    "\n",
    "def makeUrl(search, start_pg, end_pg):\n",
    "    if start_pg == end_pg:\n",
    "        start_page = makePgNum(start_pg)\n",
    "        url = \"https://search.naver.com/search.naver?where=news&sm=tab_pge&query=\" + search + \"&start=\" + str(start_page)\n",
    "        print(\"생성url: \", url)\n",
    "        return url\n",
    "    else:\n",
    "        urls = []\n",
    "        for i in range(start_pg, end_pg + 1):\n",
    "            page = makePgNum(i)\n",
    "            url = \"https://search.naver.com/search.naver?where=news&sm=tab_pge&query=\" + search + \"&start=\" + str(page)\n",
    "            urls.append(url)\n",
    "        print(\"생성url: \", urls)\n",
    "        return urls    \n",
    "\n",
    "# html에서 원하는 속성 추출하는 함수 만들기 (기사, 추출하려는 속성값)\n",
    "def news_attrs_crawler(articles,attrs):\n",
    "    attrs_content=[]\n",
    "    for i in articles:\n",
    "        attrs_content.append(i.attrs[attrs])\n",
    "    return attrs_content\n",
    "\n",
    "# ConnectionError방지\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/98.0.4758.102\"}\n",
    "\n",
    "#html생성해서 기사크롤링하는 함수 만들기(url): 링크를 반환\n",
    "def articles_crawler(url):\n",
    "    #html 불러오기\n",
    "    original_html = requests.get(i,headers=headers)\n",
    "    html = BeautifulSoup(original_html.text, \"html.parser\")\n",
    "\n",
    "    url_naver = html.select(\"div.group_news > ul.list_news > li div.news_area > div.news_info > div.info_group > a.info\")\n",
    "    url = news_attrs_crawler(url_naver,'href')\n",
    "    return url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "전체 진행:   0%|                                                                                 | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성url:  ['https://search.naver.com/search.naver?where=news&sm=tab_pge&query=삼성전자&start=1', 'https://search.naver.com/search.naver?where=news&sm=tab_pge&query=삼성전자&start=11', 'https://search.naver.com/search.naver?where=news&sm=tab_pge&query=삼성전자&start=21', 'https://search.naver.com/search.naver?where=news&sm=tab_pge&query=삼성전자&start=31', 'https://search.naver.com/search.naver?where=news&sm=tab_pge&query=삼성전자&start=41']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 99/99 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|                                                                                           | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|█▋                                                                                 | 1/49 [00:00<00:26,  1.81it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|███▍                                                                               | 2/49 [00:00<00:23,  1.98it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|█████                                                                              | 3/49 [00:01<00:21,  2.13it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|██████▊                                                                            | 4/49 [00:01<00:23,  1.90it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|████████▍                                                                          | 5/49 [00:02<00:23,  1.87it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|██████████▏                                                                        | 6/49 [00:03<00:26,  1.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|███████████▊                                                                       | 7/49 [00:03<00:25,  1.66it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█████████████▌                                                                     | 8/49 [00:04<00:21,  1.87it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|███████████████▏                                                                   | 9/49 [00:04<00:22,  1.81it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|████████████████▋                                                                 | 10/49 [00:05<00:22,  1.74it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██████████████████▍                                                               | 11/49 [00:06<00:22,  1.71it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|████████████████████                                                              | 12/49 [00:06<00:22,  1.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|█████████████████████▊                                                            | 13/49 [00:07<00:22,  1.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|███████████████████████▍                                                          | 14/49 [00:08<00:22,  1.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|█████████████████████████                                                         | 15/49 [00:08<00:22,  1.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|██████████████████████████▊                                                       | 16/49 [00:09<00:19,  1.68it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|████████████████████████████▍                                                     | 17/49 [00:09<00:18,  1.75it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 37%|██████████████████████████████                                                    | 18/49 [00:10<00:17,  1.76it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 39%|███████████████████████████████▊                                                  | 19/49 [00:11<00:18,  1.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 41%|█████████████████████████████████▍                                                | 20/49 [00:11<00:17,  1.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|███████████████████████████████████▏                                              | 21/49 [00:12<00:16,  1.72it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████████████████████████████████████▊                                             | 22/49 [00:12<00:13,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|██████████████████████████████████████▍                                           | 23/49 [00:13<00:13,  1.95it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 49%|████████████████████████████████████████▏                                         | 24/49 [00:13<00:12,  1.98it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 51%|█████████████████████████████████████████▊                                        | 25/49 [00:14<00:14,  1.67it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53%|███████████████████████████████████████████▌                                      | 26/49 [00:14<00:12,  1.80it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████████████████████████████████████████████▏                                    | 27/49 [00:15<00:14,  1.49it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 57%|██████████████████████████████████████████████▊                                   | 28/49 [00:16<00:12,  1.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 59%|████████████████████████████████████████████████▌                                 | 29/49 [00:16<00:12,  1.66it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 61%|██████████████████████████████████████████████████▏                               | 30/49 [00:17<00:10,  1.87it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 63%|███████████████████████████████████████████████████▉                              | 31/49 [00:17<00:09,  1.86it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|█████████████████████████████████████████████████████▌                            | 32/49 [00:18<00:10,  1.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|███████████████████████████████████████████████████████▏                          | 33/49 [00:18<00:08,  1.91it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 69%|████████████████████████████████████████████████████████▉                         | 34/49 [00:19<00:07,  1.90it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|██████████████████████████████████████████████████████████▌                       | 35/49 [00:19<00:07,  1.95it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 73%|████████████████████████████████████████████████████████████▏                     | 36/49 [00:20<00:07,  1.84it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 76%|█████████████████████████████████████████████████████████████▉                    | 37/49 [00:21<00:07,  1.70it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|███████████████████████████████████████████████████████████████▌                  | 38/49 [00:21<00:06,  1.72it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|█████████████████████████████████████████████████████████████████▎                | 39/49 [00:22<00:06,  1.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 82%|██████████████████████████████████████████████████████████████████▉               | 40/49 [00:22<00:05,  1.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 84%|████████████████████████████████████████████████████████████████████▌             | 41/49 [00:23<00:05,  1.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 86%|██████████████████████████████████████████████████████████████████████▎           | 42/49 [00:24<00:04,  1.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 88%|███████████████████████████████████████████████████████████████████████▉          | 43/49 [00:24<00:03,  1.79it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████████████████████████████████████████████████████████████████████▋        | 44/49 [00:25<00:02,  2.09it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 92%|███████████████████████████████████████████████████████████████████████████▎      | 45/49 [00:25<00:01,  2.27it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 94%|████████████████████████████████████████████████████████████████████████████▉     | 46/49 [00:25<00:01,  2.12it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 96%|██████████████████████████████████████████████████████████████████████████████▋   | 47/49 [00:26<00:00,  2.09it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 98%|████████████████████████████████████████████████████████████████████████████████▎ | 48/49 [00:27<00:00,  1.75it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:27<00:00,  1.76it/s]\u001b[A\n",
      "전체 진행:  50%|████████████████████████████████████▌                                    | 1/2 [00:30<00:30, 30.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  46\n",
      "생성url:  ['https://search.naver.com/search.naver?where=news&sm=tab_pge&query=하이닉스&start=1', 'https://search.naver.com/search.naver?where=news&sm=tab_pge&query=하이닉스&start=11', 'https://search.naver.com/search.naver?where=news&sm=tab_pge&query=하이닉스&start=21', 'https://search.naver.com/search.naver?where=news&sm=tab_pge&query=하이닉스&start=31', 'https://search.naver.com/search.naver?where=news&sm=tab_pge&query=하이닉스&start=41']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 86/86 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|                                                                                           | 0/36 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|██▎                                                                                | 1/36 [00:00<00:22,  1.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|████▌                                                                              | 2/36 [00:01<00:20,  1.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|██████▉                                                                            | 3/36 [00:01<00:18,  1.76it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█████████▏                                                                         | 4/36 [00:02<00:18,  1.74it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|███████████▌                                                                       | 5/36 [00:02<00:16,  1.83it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█████████████▊                                                                     | 6/36 [00:03<00:15,  1.99it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|████████████████▏                                                                  | 7/36 [00:03<00:14,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██████████████████▍                                                                | 8/36 [00:04<00:14,  1.87it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|████████████████████▊                                                              | 9/36 [00:04<00:12,  2.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██████████████████████▊                                                           | 10/36 [00:05<00:12,  2.13it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|█████████████████████████                                                         | 11/36 [00:05<00:11,  2.24it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███████████████████████████▎                                                      | 12/36 [00:05<00:09,  2.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 36%|█████████████████████████████▌                                                    | 13/36 [00:06<00:10,  2.24it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 39%|███████████████████████████████▉                                                  | 14/36 [00:06<00:10,  2.16it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|██████████████████████████████████▏                                               | 15/36 [00:07<00:09,  2.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|████████████████████████████████████▍                                             | 16/36 [00:07<00:08,  2.24it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|██████████████████████████████████████▋                                           | 17/36 [00:08<00:08,  2.33it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████████████████████████████████████████                                         | 18/36 [00:08<00:09,  1.94it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53%|███████████████████████████████████████████▎                                      | 19/36 [00:09<00:08,  2.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████████████████████████████████████████████▌                                    | 20/36 [00:09<00:08,  1.99it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 58%|███████████████████████████████████████████████▊                                  | 21/36 [00:10<00:07,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 61%|██████████████████████████████████████████████████                                | 22/36 [00:10<00:07,  1.77it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 64%|████████████████████████████████████████████████████▍                             | 23/36 [00:11<00:07,  1.83it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████████████████████████████████████████████████████▋                           | 24/36 [00:11<00:06,  1.96it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 69%|████████████████████████████████████████████████████████▉                         | 25/36 [00:12<00:05,  2.06it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 72%|███████████████████████████████████████████████████████████▏                      | 26/36 [00:12<00:05,  1.97it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 27/36 [00:13<00:05,  1.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|███████████████████████████████████████████████████████████████▊                  | 28/36 [00:14<00:04,  1.87it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 81%|██████████████████████████████████████████████████████████████████                | 29/36 [00:14<00:03,  2.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|████████████████████████████████████████████████████████████████████▎             | 30/36 [00:14<00:02,  2.04it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 86%|██████████████████████████████████████████████████████████████████████▌           | 31/36 [00:15<00:02,  1.89it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 89%|████████████████████████████████████████████████████████████████████████▉         | 32/36 [00:16<00:02,  1.72it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 92%|███████████████████████████████████████████████████████████████████████████▏      | 33/36 [00:16<00:01,  1.89it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████▍    | 34/36 [00:17<00:01,  1.77it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████▋  | 35/36 [00:17<00:00,  1.88it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:18<00:00,  1.95it/s]\u001b[A\n",
      "전체 진행: 100%|█████████████████████████████████████████████████████████████████████████| 2/2 [00:51<00:00, 25.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  34\n",
      "모든 기업에 대한 뉴스 요약이 완료되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
    "import numpy as np\n",
    "#엑셀 파일에서 데이터 불러오기\n",
    "file_path = './기업명_리스트_시범2.csv'  # 엑셀 파일 경로\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 뉴스 요약 컬럼 생성\n",
    "df['뉴스요약'] = ''\n",
    "\n",
    "# 기업명별로 뉴스 요약 생성하여 추가\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"전체 진행\"):\n",
    "    \n",
    "    #####뉴스크롤링 시작#####\n",
    "\n",
    "    #검색어 입력\n",
    "    search = row['기업명']\n",
    "    #검색 시작할 페이지 입력\n",
    "    page = 1\n",
    "    #검색 종료할 페이지 입력\n",
    "    page2 = 5\n",
    "\n",
    "\n",
    "    # naver url 생성\n",
    "    url = makeUrl(search,page,page2)\n",
    "\n",
    "    #뉴스 크롤러 실행\n",
    "    news_titles = []\n",
    "    news_url =[]\n",
    "    news_contents =[]\n",
    "    news_dates = []\n",
    "    for i in url:\n",
    "        url = articles_crawler(url)\n",
    "        news_url.append(url)\n",
    "\n",
    "\n",
    "    #제목, 링크, 내용 1차원 리스트로 꺼내는 함수 생성\n",
    "    def makeList(newlist, content):\n",
    "        for i in content:\n",
    "            for j in i:\n",
    "                newlist.append(j)\n",
    "        return newlist\n",
    "\n",
    "    \n",
    "    #제목, 링크, 내용 담을 리스트 생성\n",
    "    news_url_1 = []\n",
    "\n",
    "    #1차원 리스트로 만들기(내용 제외)\n",
    "    makeList(news_url_1,news_url)\n",
    "\n",
    "    #NAVER 뉴스만 남기기\n",
    "    final_urls = []\n",
    "    for i in tqdm(range(len(news_url_1))):\n",
    "        if \"news.naver.com\" in news_url_1[i]:\n",
    "            final_urls.append(news_url_1[i])\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # 뉴스 내용 크롤링\n",
    "\n",
    "    for i in tqdm(final_urls):\n",
    "        #각 기사 html get하기\n",
    "        news = requests.get(i,headers=headers)\n",
    "        news_html = BeautifulSoup(news.text,\"html.parser\")\n",
    "\n",
    "        # 뉴스 제목 가져오기\n",
    "        title = news_html.select_one(\"#ct > div.media_end_head.go_trans > div.media_end_head_title > h2\")\n",
    "        if title == None:\n",
    "            title = news_html.select_one(\"#content > div.end_ct > div > h2\")\n",
    "    \n",
    "        # 뉴스 본문 가져오기\n",
    "        content = news_html.select(\"article#dic_area\")\n",
    "        if content == []:\n",
    "            content = news_html.select(\"#articeBody\")\n",
    "\n",
    "        # 기사 텍스트만 가져오기\n",
    "        #list합치기\n",
    "        content = ''.join(str(content))\n",
    "\n",
    "        # html태그제거 및 텍스트 다듬기\n",
    "        pattern1 = '<[^>]*>'\n",
    "        title = re.sub(pattern=pattern1, repl='', string=str(title))\n",
    "        content = re.sub(pattern=pattern1, repl='', string=content)\n",
    "        pattern2 = \"\"\"[\\n\\n\\n\\n\\n// flash 오류를 우회하기 위한 함수 추가\\nfunction _flash_removeCallback() {}\"\"\"\n",
    "        content = content.replace(pattern2, '')\n",
    "\n",
    "        news_titles.append(title)\n",
    "        news_contents.append(content)\n",
    "\n",
    "        try:\n",
    "            html_date = news_html.select_one(\"div#ct> div.media_end_head.go_trans > div.media_end_head_info.nv_notrans > div.media_end_head_info_datestamp > div > span\")\n",
    "            news_date = html_date.attrs['data-date-time']\n",
    "        except AttributeError:\n",
    "            news_date = news_html.select_one(\"#content > div.end_ct > div > div.article_info > span > em\")\n",
    "            news_date = re.sub(pattern=pattern1,repl='',string=str(news_date))\n",
    "        # 날짜 가져오기\n",
    "        news_dates.append(news_date)\n",
    "\n",
    "#print(\"검색된 기사 갯수: 총 \",(page2+1-page)*10,'개')\n",
    "#print(\"\\n[뉴스 제목]\")\n",
    "#print(news_titles)\n",
    "#print(\"\\n[뉴스 링크]\")\n",
    "#print(final_urls)\n",
    "#print(\"\\n[뉴스 내용]\")\n",
    "#print(news_contents)\n",
    "\n",
    "#print('news_title: ',len(news_titles))\n",
    "#print('news_url: ',len(final_urls))\n",
    "#print('news_contents: ',len(news_contents))\n",
    "#print('news_dates: ',len(news_dates))\n",
    "\n",
    "        ###데이터 프레임으로 만들기###\n",
    "\n",
    "        #데이터 프레임 만들기\n",
    "        news_df = pd.DataFrame({'corp_name':search,'content':news_contents})\n",
    "\n",
    "        #중복 행 지우기\n",
    "        news_df = news_df.drop_duplicates(keep='first',ignore_index=True)\n",
    "        print(\"중복 제거 후 행 개수: \",len(news_df))\n",
    "    \n",
    "\n",
    " # 최종 결과를 엑셀 파일로 저장\n",
    "output_path = './final.csv'  # 결과 파일 경로\n",
    "news_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"모든 기업에 대한 뉴스 요약이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n\\n\\n\\n\\n [사진출처=연합뉴스]지난 4월 미국 정부로부터 약 9조원의 보조금을 확정지은 삼성전자에 이어 SK하이닉스 역시 반도체 보조금을 지원받는다.6일(현지시간) 미 상무부는 SK하이닉스와 HBM 고급 패키징 제조, 연구개발(R&amp;D) 시설 설립을 위해 최대 4억5000만달러(6200억원)의 직접보조금과 5억달러(6900억원)의 대출을 지원하는 내용의 예비거래각서(PMT)를 체결했다고 밝혔다.아울러 미 상무부는 SK하이닉스가 미국에서 투자하는 금액의 최대 25%까지 세액 공제 혜택을 제공해 준다고 밝혔다. 최종 지원금은 미 상무부 반도체법 재정 인센티브 세부 지원계획(NOFO)의 절차에 따라 결정될 예정이다.이로써 SK하이닉스는 미국 인디애나주 웨스트라피엣에 반도체 패키징 생산기지 건설을 시작하고 미국 시장 공략에 속도를 낸다는 방침이다.곽노정 SK하이닉스 사장은 “미국 상무부의 지원에 깊은 감사의 뜻을 전하며 이 프로젝트가 완전히 실현되는데 협력할 수 있어 기쁘다”며 “AI 기술을 위한 새로운 허브를 구축하고 인디애나에서 숙련된 일자리를 창출하며 글로벌 반도체 산업을 위한 강력하고 회복력 있는 공급망을 구축하는 데 기여할 수 있길 기대한다”고 말했다.투자금 대비 보조금 비율…삼성 14.2%·SK 11.6%이번 보조금은 조 바이든 대통령이 지난 2022년 제정한 ‘반도체 및 과학법(Chips and Science Act)’에 따른 것이다.미국은 반도체 기업의 미국 내 설비투자를 장려하기 위해 미국에 공장을 짓는 기업에 반도체 생산 보조금으로 총 390억달러(약 52조3000억원), R&amp;D 지원금 132억달러(18조원) 등 5년간 총 527억달러(70조7000억원)을 지원하기로 했다.칩스법에 수혜 대상에는 세계 5대 칩 제조업체가 모두 포함됐다. 삼성전자 64억달러(8조8000억원)을 포함해 ▲TSMC(66억달러·9조) ▲인텔(85억달러·11조7000억원) ▲마이크론테크놀로지(61억달러·8조3000억원) ▲SK하이닉스(4억5000만달러·6200억원) 등이다.SK하이닉스는 경쟁사 대비 투자 규모가 크지 않은 만큼 지원금도 작은 편이다. 다만 투자 금액 대비 보조금 비중은 11.6%로 TSMC(10.2%)와 인텔(8.5%)에 비하면 높은 수준이다. 텍사스주 첨단 반도체 공장 투자로 보조금 64억달러를 받게 된 삼성전자의 투자 금액(450억달러) 대비 직접 보조금 비중은 14.2% 수준이다.\\n\\n\\n\\n 삼성전자, 미국 텍사스주 테일러 파운드리 공장 건설 현장. [사진출처=삼성전자]미 텍사스주 테일러시에 반도체 공장을 짓고 있는 삼성전자는 지난 4월 미 정부로부터 64억달러를 보조금으로 지급받는 내용의 예비협약을 상무부와 체결한 바 있다. 삼성전자는 기존에 발표한 투자액인 170억달러의 두 배가 넘는 금액인 400억달러(55조 3600억원) 이상을 투자하기로 했다.삼성전자의 테일러공장은 지난 2022년 상반기 착공했다. 지난해 말 기준 공사 진행률은 59.7%다.당초 업계에서는 SK하이닉스의 보조금 발표가 지연되면서 촉각을 곤두세워왔다. 오는 11월 미국 대선을 앞두고 있는 만큼 미 정부의 정책 변화 가능성이 꾸준히 대두됐기 때문이다.다만 자국 기업에 대한 지원을 늘리고 외국 반도체 기업에 지원금을 축소한다는 트럼프의 당선 가능성이 높아 여전히 안심하기는 이르다는 의견도 나온다. 여기에 최근 중국에 대한 반도체 압박 수위를 높이고 있어 국내 기업에 미치는 영향도 살펴봐야한다는 설명이다.업계 한 관계자는 “아무리 트럼프가 대통령으로 당선된다 하더라도 기존 발표한 반도체 보조금 정책을 완전히 뒤바꿀 수는 없을 것”이라며 “다만 보조금 지급을 축소하거나 추가 투자를 유도하는 등의 방식으로 변경할 수 있어 보조금이 기업들에 실제 지급될 때까지 지켜봐야 할 것”이라고 말했다.한편 NYT 보도에 따르면 미 행정부는 올해 안으로 기업들에게 보조금을 분배할 것으로 알려졌다.\\n]'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['content'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
